---
title: "Example-AKAP79"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Example-AKAP79}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This example covers the AKAP79 example model and `rgsl` as solver
backend, alternatively, it is possible to use `deSolve` instead (but
not covered here).

We use `icpm-kth/SBtabVFGEN` to read the model files and `icpm-kth/rgsl` as an
interface to `gsl_odeiv2` solvers (for initial value problems) to simulate the model:

```{r setup}
library(uqsa)
require(SBtabVFGEN)
require(rgsl)
require(parallel)
```

Next, we import the model's data tables from the SBtab files:

```{r read-model, eval=FALSE}
modelName <- checkModel("AKAP79",uqsa_example("AKAP79",pat="gvf[.]c$"))
model.tsv <- uqsa_example(modelName,pat="[.]tsv$")
model <- SBtabVFGEN::sbtab_from_tsv(model.tsv)
experiments <- SBtabVFGEN::sbtab.data(model.tsv)
```

The function `checkModel` checks that the model files exist and
compiles the model to a shared library using a c compiler, the gsl
library needs to be installed on the system for this to work (file
ending in `.so`). On windows, it is easier to use the `deSolve`
solvers.

The `model` variable contains the tabulated properties of the model as
a `list` of `data.frames`. The source files of the model `AKAP79.R`,
`AKAP79.vf`, and `AKAP79_gvf.c` were all created automatically from
the tables. Because they are tables, we can retrieve default values
from them.

```{r defaults, eval=FALSE}
parVal <- model$Parameter[["!DefaultValue"]]

parMap <- function(parABC){
	return(10^parABC)
}
```

We have also defined a function that will transform the sampling
variables `parABC` used by the ABC method into something that the model will accept as parameters. The plan
is to sample in logarithmic space: the ABC algorithm will sample the
logarithms of the model parameters. We limit the sampling to ranges,
as appropriate for each parameter:

```{r bounds, eval=FALSE}
defRange <- 1000

# Define Lower and Upper Limits for logUniform prior distribution for the parameters

ll <- c(parVal[1:19]/defRange,
       parVal[20]/1.9,
       parVal[21]/defRange,
       parVal[22:24]/1.25,
       parVal[25:26]/1.5,
       parVal[27]/2
      )
ul <- c(parVal[1:19]*defRange,
       parVal[20]*1.9,
       parVal[21]*defRange,
       parVal[22:24]*1.25,
       parVal[25:26]*1.5,
       parVal[27]*2
      )
ll = log10(ll) # log10-scale
ul = log10(ul) # log10-scale
```

The sampling procedure takes data in the list of `experiments` and
compares the data points to the solution that `gsl_odeiv2` returns. We
define a list of experiments, subdividing them into smaller groups and
processing the groups in sequence. Between the rounds of sampling the
posterior of every result is used as the prior distribution of the
next round. This mimics the arrival of data sets in sequence (from the
lab). The intermediate distributions will be modelled using
`VineCopula`.

```{r schedule, eval=FALSE}
experimentsIndices <- list(c(3, 12,18, 9), c(2, 11, 17, 8), c(1, 10, 16, 7))
```

ABC procedure setup:

```{r sample-size, eval=FALSE}
ns <- 5000 # Size of the sub-sample from each chain
npc <- 1000 # pre-calibration sample size
nChains <- 16
n <- ns*nChains
options(mc.cores=parallel::detectCores() %/% nChains)

delta <- 1

set.seed(7619201)

Score <- function(yy_sim, yy_exp=Inf, yy_expErr=Inf){
	distance <- mean(((yy_sim-yy_exp)/yy_expErr)^2, na.rm=TRUE)
	return(distance)
}
```

We also setup a convenience function which saves the sampled values to a file:

```{r save, eval=FALSE}
save_sample <- function(ind,ABCMCMCoutput){
	I <- paste(ind, collapse="_")
	timeStr <- Sys.time()
	timeStr <- gsub(":","_", timeStr)
	timeStr <- gsub(" ","_", timeStr)
	if (!dir.exists("./PosteriorSamples")) {
		dir.create("./PosteriorSamples")
	}
	outFileR <- paste("./PosteriorSamples/Draws",modelName,"nChains",nChains,"ns",ns,"npc",npc,I,timeStr,".RData",collapse="_",sep="_")
	save(ABCMCMCoutput, file=outFileR)
}
```

The sampling loop:

```{r sample, eval=FALSE}
start_time = Sys.time()
for (i in 1:length(experimentsIndices)){
	expInd <- experimentsIndices[[i]]
	objectiveFunction <- makeObjective(experiments[expInd], modelName, Score, parMap)
	if (i==1){
		rprior <- rUniformPrior(ll, ul)
		dprior <- dUniformPrior(ll, ul)
	} else {
		C <- fitCopula(ABCMCMCoutput$draws, nCores)
		rprior <- rCopulaPrior(C)
		dprior <- dCopulaPrior(C)
	}
	pC <- preCalibration(objectiveFunction, npc, rprior)
	M <- getMCMCPar(pC$prePar, pC$preDelta, delta=delta, num = nChains)
	M$startPar <- matrix(M$startPar, nrow=nChains)
	cl <- makeForkCluster(nChains)
	clusterExport(cl, c("objectiveFunction", "M", "ns", "delta", "dprior", "acceptanceProbability"))
	out_ABCMCMC <- parLapply(cl, 1:nChains, function(j) ABCMCMC(objectiveFunction, M$startPar[j,], ns, M$Sigma, delta, dprior, acceptanceProbability))
	stopCluster(cl)
	ABCMCMCoutput <- do.call(Map, c(rbind,out_ABCMCMC))
	save_sample(expInd,ABCMCMCoutput)
}
end_time = Sys.time()
time_ = end_time - start_time

cat("Total time:\n",time_)
```

The result is a collection of intermediate samples (2 files) and a final posterior sample (1 file).
